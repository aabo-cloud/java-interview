## 大数据



### 离线批处理场景

#### 概念

离线批处理，是指对海量历史数据进行处理和分析，生成结果数据，供下一步使用的过程。

* 处理时延要求不高
* 处理数据量大，占用存储资源多
* 处理数据格式多样
* 支持SQL类作业和自定义作业

#### 离线批处理流程

![image-20250406133355971](大数据.assets/image-20250406133355971.png)



### HDFS

`HDFS(Hadoop Distributed File System)`是基于Google发布的`GFS(Google File System)`论文设计开发的分布式文件系统，为各种批处理引擎提供数据存储，可以存储各种文件格式数据。

* 高容错性：认为硬件不可靠。由于HDFS采用数据多副本方案，所以部分硬件的损坏不会导致全部数据的丢失。
* 高吞吐量：为大量数据访问的应用提供高吞吐量支持。
* 大文件存储：适合`大文件（TB-PB级别）`存储存储与访问、`流式数据`访问；不适合大量小文件存储，数据的随机写入和低延迟读取。
* 简单一致性模型：适合于一次写入多次读取 (write-once-read-many) 的访问模型。支持将内容追加到文件末尾， 但不支持数据的随机访问，不能从文件任意位置新增数据。
* 跨平台移植性

#### HDFS架构

![image-20250406135032095](大数据.assets/image-20250406135032095.png)



HDFS为主/从架构，由单个`NameNode(NN)`和多个`DataNode(DN)`组成：

* `NameNode`：负责执行有关`文件系统命名空间`的操作，例如打开，关闭、重命名文件和目录等，并记录对命名空间的修改。 它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。HDFS`文件系统命名空间`的层次结构与Linux系统类似， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。
* `DataNode`：负责执行来自文件系统客户端的读写请求，执行块的创建，删除等操作。

#### 数据复制

为了保证容错性，HDFS提供了数据复制机制。HDFS将每一个文件存储为一系列**块**，每个块由多个**副本**来保证容错，块的大小和**复制因子**可以自行配置（默认情况下，块大小是`128M`，默认复制因子是`3`）。

大型的HDFS实例在通常分布在多个机架的多台服务器上，不同机架上的两台服务器之间通过交换机进行通讯。在大多数情况下，同一机架中的服务器间的网络带宽大于不同机架中的服务器之间的带宽。

因此HDFS采用`机架感知副本放置策略`，当复制因子为3时，HDFS的放置策略是： 

？在写入程序位于  datanode 上时，就优先将写入文件的一个副本放置在该  datanode 上，否则放在随 机 datanode 上。之后在另一个远程机架上的任意一个节点上放置另一个副本，并在该机架上的另一 个节点上放置最后一个副本。此策略可以减少机架间的写入流量，从而提高写入性能。

如果复制因子大于 3，则随机确定第 4 个和之后副本的放置位置，同时保持每个机架的副本数量低于上 限，上限值通常为（复制系数 - 1）/机架数量 + 2，需要注意的是不允许同一个  dataNode 上具有同一个块的多个副本。



#### HDFS回收站机制

在HDFS删除文件时，其实是将文件放入回收站，回收站可以用来快速恢复误删的文件。

可以设置时间阈值（单位：分钟），当回收站里的文件存放时间超过这个阈值或清空回收站时，文件才会被彻底删除，并释放占用的数据块。

Hadoop回收站trash，默认是关闭的，若开启需要修改配置文件`core-site.xml`。

```xml
<property>
	<name>fs.trash.interval</name>
	<value>1440</value>
</property>
```



如何删除数据



### MapReduce

Hadoop MapReduce 是一个分布式计算框架，用于编写批处理应用程序。编写好的程序可以提交到  Hadoop 集群上用于并行处理大规模的数据集



### Hive



















### 实时检索场景



### 实时流处理场景





### Presto

#### 时间转换

```sql
# 字符串转date
select cast(substr('2021-05-25 00:00:00.0', 1, 10) as date);

# 字符串转time型时间戳
select cast('2021-05-25 00:00:00.0' as timestamp);

# 字符串转time型时间戳转long型时间戳
select to_unixtime(cast('2021-05-25 00:00:00.0' as timestamp));

# 
select format_datetime(from_unixtime(to_unixtime(cast('2021-05-25 00:00:00.0' as timestamp))), 'yyyy-MM-dd HH:mm:ss');

# 
format_datetime(from_unixtime(to_unixtime(cast(substr('2021-05-25 00:00:00.0', 1, 10) as date))), 'yyyy-MM-dd');


```

