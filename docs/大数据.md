## 大数据



### 离线批处理场景

离线批处理，是指对海量历史数据进行处理和分析，生成结果数据，供下一步使用的过程。

* 处理时延要求不高
* 处理数据量大，占用存储资源多
* 处理数据格式多样
* 支持SQL类作业和自定义作业

离线批处理流程

![image-20250406133355971](大数据.assets/image-20250406133355971.png)



#### HDFS

`HDFS(Hadoop Distributed File System)`是基于Google发布的`GFS(Google File System)`论文设计开发的分布式文件系统，为各种批处理引擎提供数据存储，可以存储各种文件格式数据。

* 高容错性：认为硬件不可靠。由于HDFS采用数据多副本方案，所以部分硬件的损坏不会导致全部数据的丢失。
* 高吞吐量：为大量数据访问的应用提供高吞吐量支持。
* 大文件存储：适合`大文件（TB-PB级别）`存储存储与访问、`流式数据`访问；不适合大量小文件存储，数据的随机写入和低延迟读取。
* 简单一致性模型：适合于一次写入多次读取 (write-once-read-many) 的访问模型。支持将内容追加到文件末尾， 但不支持数据的随机访问，不能从文件任意位置新增数据。
* 跨平台移植性

##### HDFS架构

![image-20250406135032095](大数据.assets/image-20250406135032095.png)



HDFS为主/从架构，由单个`NameNode(NN)`和多个`DataNode(DN)`组成：

* `NameNode`：负责执行有关`文件系统命名空间`的操作，例如打开，关闭、重命名文件和目录等，并记录对命名空间的修改。 它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。HDFS`文件系统命名空间`的层次结构与Linux系统类似， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。
* `DataNode`：负责执行来自文件系统客户端的读写请求，执行块的创建，删除等操作。

##### 数据复制

为了保证容错性，HDFS提供了数据复制机制。HDFS将每一个文件存储为一系列**块**，每个块由多个**副本**来保证容错，块的大小和**复制因子**可以自行配置（默认情况下，块大小是`128M`，默认复制因子是`3`）。

大型的HDFS实例在通常分布在多个机架的多台服务器上，不同机架上的两台服务器之间通过交换机进行通讯。在大多数情况下，同一机架中的服务器间的网络带宽大于不同机架中的服务器之间的带宽。

因此HDFS采用`机架感知副本放置策略`，当复制因子为3时，HDFS的放置策略是： 

？在写入程序位于  datanode 上时，就优先将写入文件的一个副本放置在该  datanode 上，否则放在随 机 datanode 上。之后在另一个远程机架上的任意一个节点上放置另一个副本，并在该机架上的另一 个节点上放置最后一个副本。此策略可以减少机架间的写入流量，从而提高写入性能。

如果复制因子大于 3，则随机确定第 4 个和之后副本的放置位置，同时保持每个机架的副本数量低于上 限，上限值通常为（复制系数 - 1）/机架数量 + 2，需要注意的是不允许同一个  dataNode 上具有同一个块的多个副本。



##### HDFS回收站机制

在HDFS删除文件时，其实是将文件放入回收站，回收站可以用来快速恢复误删的文件。

可以设置时间阈值（单位：分钟），当回收站里的文件存放时间超过这个阈值或清空回收站时，文件才会被彻底删除，并释放占用的数据块。

Hadoop回收站trash，默认是关闭的，若开启需要修改配置文件`core-site.xml`。

```xml
<property>
	<name>fs.trash.interval</name>
	<value>1440</value>
</property>
```



如何删除数据？

##### 常用Shell命令

```shell
# 显示文件内容
hdfs dfs -cat
# 显示目录列表
hdfs dfs -ls
# 
hdfs dfs -rm
hdfs dfs -put 
hdfs dfs -get
hdfs dfs -mkdir
# 修改文件或目录的权限
hdfs dfs -chmod
# 修改文件或目录的所有者和所属组
hdfs dfs -chown
# 安全模式操作
hdfs dfsadmin -safemode
# 报告服务状态
hdfs dfsadmin -report

```

#### MapReduce

Hadoop MapReduce 是一个分布式计算框架，用于编写批处理应用程序。编写好的程序可以提交到  Hadoop 集群上用于并行处理大规模的数据集



#### Hive

Hive是基于Hadoop的数据仓库软件，可以查询和管理PB级别的分布式数据。

Hive特性：

* 灵活`ETL（Extract/Transform/Load）`
* 支持MapReduce、Tez、Spark多种计算引擎
* 可直接访问HDFS文件以及HBase
* 易用易编程



##### Hive架构



##### Hive数据存储模型

![image-20250508214033566](/Users/siboo/Library/Application Support/typora-user-images/image-20250508214033566.png)

Hive内部表和外部表的区别



##### 数据集市

数据集市（Data Mart）：也叫数据市场，数据集市就是满足特定用户的需求，按照多维的方式存储数据，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体。

##### 数据仓库

为满足各类零散分析的需求，通过数据分层和数据模型的方式，并以基于业务和应用的角度将数据进行模块化的存储。

数据仓库分层：

* ODS（Operational Data Store）：原始数据层。
* DWD（Data WareHouse Detail）：结构和粒度与原始数据保持一致，简单清洗。
* DWS（Data WareHouse Service）：以DWD为基础，进行轻度汇总。
* ADS（Application Data Store）：为各种统计报表提供数据。

分层优点：

* 复杂问题简单化：将任务分解为多个步骤完成，每一层处理单一的任务。
* 减少重复开发：规范数据分层，通过中间层数据，减少重复计算，增加计算结果的复用性。
* 隔离原始数据：避免数据异常和数据敏感，使真实数据和统计数据解耦。

#### Spark

Spark是基于内存的分布式批处理系统。













### 实时检索场景



### 实时流处理场景



