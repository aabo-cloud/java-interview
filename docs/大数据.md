## 大数据



### 离线批处理场景

离线批处理，是指对海量历史数据进行处理和分析，生成结果数据，供下一步使用的过程。

* 处理时延要求不高
* 处理数据量大，占用存储资源多
* 处理数据格式多样
* 支持SQL类作业和自定义作业

离线批处理流程

![image-20250406133355971](大数据.assets/image-20250406133355971.png)



#### Hadoop

核心组件：HDFS、YARN、MapReduce、Hadoop Common

生态系统工具：

- **计算引擎**：Spark（内存计算）、Flink（流处理）、Tez（优化 DAG 执行）。
- **数据仓库**：Hive（Hive 3.x 支持 LLAP 实时查询）、Impala。
- **NoSQL 存储**：HBase（基于 HDFS 的列式数据库）。
- **协调服务**：ZooKeeper（集群协调）、Apache Atlas（元数据治理）。



#### HDFS

`HDFS(Hadoop Distributed File System)`是基于Google发布的`GFS(Google File System)`论文设计开发的分布式文件系统，为各种批处理引擎提供数据存储，可以存储各种文件格式数据。

* 高容错性：认为硬件不可靠。由于HDFS采用数据多副本方案，所以部分硬件的损坏不会导致全部数据的丢失。
* 高吞吐量：为大量数据访问的应用提供高吞吐量支持。
* 大文件存储：适合`大文件（TB-PB级别）`存储存储与访问、`流式数据`访问；不适合大量小文件存储，数据的随机写入和低延迟读取。
* 简单一致性模型：适合于一次写入多次读取 (write-once-read-many) 的访问模型。支持将内容追加到文件末尾， 但不支持数据的随机访问，不能从文件任意位置新增数据。
* 跨平台移植性

##### HDFS架构

![image-20250406135032095](大数据.assets/image-20250406135032095.png)



HDFS为主/从架构，由单个`NameNode(NN)`和多个`DataNode(DN)`组成：

* `NameNode`：负责执行有关`文件系统命名空间`的操作，例如打开，关闭、重命名文件和目录等，并记录对命名空间的修改。 它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。HDFS`文件系统命名空间`的层次结构与Linux系统类似， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。
* `DataNode`：负责执行来自文件系统客户端的读写请求，执行块的创建，删除等操作。

##### 数据复制

为了保证容错性，HDFS提供了数据复制机制。HDFS将每一个文件存储为一系列**块**，每个块由多个**副本**来保证容错，块的大小和**复制因子**可以自行配置（默认情况下，块大小是`128M`，默认复制因子是`3`）。

大型的HDFS实例在通常分布在多个机架的多台服务器上，不同机架上的两台服务器之间通过交换机进行通讯。在大多数情况下，同一机架中的服务器间的网络带宽大于不同机架中的服务器之间的带宽。

因此HDFS采用`机架感知副本放置策略`，当复制因子为3时，HDFS的放置策略是： 

？在写入程序位于  datanode 上时，就优先将写入文件的一个副本放置在该  datanode 上，否则放在随 机 datanode 上。之后在另一个远程机架上的任意一个节点上放置另一个副本，并在该机架上的另一 个节点上放置最后一个副本。此策略可以减少机架间的写入流量，从而提高写入性能。

如果复制因子大于 3，则随机确定第 4 个和之后副本的放置位置，同时保持每个机架的副本数量低于上 限，上限值通常为（复制系数 - 1）/机架数量 + 2，需要注意的是不允许同一个  dataNode 上具有同一个块的多个副本。



##### HDFS回收站机制

在HDFS删除文件时，其实是将文件放入回收站，回收站可以用来快速恢复误删的文件。

可以设置时间阈值（单位：分钟），当回收站里的文件存放时间超过这个阈值或清空回收站时，文件才会被彻底删除，并释放占用的数据块。

Hadoop回收站trash，默认是关闭的，若开启需要修改配置文件`core-site.xml`。

```xml
<property>
	<name>fs.trash.interval</name>
	<value>1440</value>
</property>
```



如何删除数据？

##### 常用Shell命令

```shell
# 显示文件内容
hdfs dfs -cat
# 显示目录列表
hdfs dfs -ls
# 
hdfs dfs -rm
hdfs dfs -put 
hdfs dfs -get
hdfs dfs -mkdir
# 修改文件或目录的权限
hdfs dfs -chmod
# 修改文件或目录的所有者和所属组
hdfs dfs -chown
# 安全模式操作
hdfs dfsadmin -safemode
# 报告服务状态
hdfs dfsadmin -report

```

#### MapReduce

Hadoop MapReduce 是一个分布式计算框架，用于编写批处理应用程序。编写好的程序可以提交到  Hadoop 集群上用于并行处理大规模的数据集



#### Hive

Hive是基于Hadoop的数据仓库软件，可以查询和管理PB级别的分布式数据。

Hive特性：

* 灵活`ETL（Extract/Transform/Load）`
* 支持MapReduce、Tez、Spark多种计算引擎
* 可直接访问HDFS文件以及HBase
* 易用易编程



##### Hive架构



##### Hive数据存储模型

![image-20250508214033566](/Users/siboo/Library/Application Support/typora-user-images/image-20250508214033566.png)

###### 表（Table）

Hive 的**基本数据单元**，类似于关系型数据库中的表，但数据存储在 HDFS 上。

- 内部表（Managed Table）
  - 管理表的元数据和数据。删除表时，元数据和 HDFS 上的数据会被一并删除。
  - 默认存储路径：`/user/hive/warehouse/<database>.db/<table>`。
- 外部表（External Table）
  - 仅管理元数据，数据存储在用户指定的 HDFS 路径中。删除表时，仅删除元数据，数据保留。
  - 适用场景：与其他工具（如 Spark、Pig）共享数据，避免误删数据。

###### 分区（Partition）

- **作用**：按某个字段的值（如日期、地区）将数据划分为不同的子目录，**减少查询时的数据扫描量**。
- 存储方式：每个分区对应 HDFS 上的一个子目录。
  - 示例：按 `date` 分区的表路径为 `/user/hive/warehouse/logs/date=2023-10-01/`。
- **适用场景**：常用于时间序列数据或高基数字段（如国家、城市）。

###### 分桶（Bucketing）

- **作用**：对数据按哈希值分桶，每个桶对应一个文件，**优化 JOIN 和采样效率**。
- 存储方式：数据按分桶字段的哈希值分配到固定数量的桶中。
  - 示例：按 `user_id` 分 10 个桶，相同 `user_id` 的数据落在同一个桶文件。
- **适用场景**：需要高效 JOIN 或频繁数据采样的场景。

##### UDF（User-Defined Function，用户自定义函数）

当 Hive 内置函数无法满足特定需求时（如复杂字符串处理、数据清洗、业务逻辑封装），可通过 UDF 实现：

- **数据转换**：例如将手机号脱敏、解析 JSON 字段。
- **复杂计算**：例如自定义聚合、地理哈希编码。
- **适配外部系统**：例如调用外部 API 或算法模型。

| **类型** |             **全称**              |        **输入/输出**        |                 **示例**                 |
| :------: | :-------------------------------: | :-------------------------: | :--------------------------------------: |
| **UDF**  |       User-Defined Function       |     单行输入 → 单行输出     |         字符串转大写、日期格式化         |
| **UDAF** | User-Defined Aggregation Function | 多行输入 → 单行输出（聚合） |      自定义统计指标（如分位数计算）      |
| **UDTF** |    User-Defined Table Function    |  单行输入 → 多行/多列输出   | 将 JSON 数组拆分为多行（类似 `EXPLODE`） |

##### 数据集市

数据集市（Data Mart）：也叫数据市场，数据集市就是满足特定用户的需求，按照多维的方式存储数据，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体。

##### 数据仓库

为满足各类零散分析的需求，通过数据分层和数据模型的方式，并以基于业务和应用的角度将数据进行模块化的存储。

数据仓库分层：

* ODS（Operational Data Store）：原始数据层。
* DWD（Data WareHouse Detail）：结构和粒度与原始数据保持一致，简单清洗。
* DWS（Data WareHouse Service）：以DWD为基础，进行轻度汇总。
* ADS（Application Data Store）：为各种统计报表提供数据。

分层优点：

* 复杂问题简单化：将任务分解为多个步骤完成，每一层处理单一的任务。
* 减少重复开发：规范数据分层，通过中间层数据，减少重复计算，增加计算结果的复用性。
* 隔离原始数据：避免数据异常和数据敏感，使真实数据和统计数据解耦。

#### Spark

Spark是基于内存的分布式批处理系统，它把任务拆分，分配到多个CPU上进行处理，处理数据时产生的中间产物（计算结果）存放在内存中，减少了对磁盘的IO操作，提升了数据处理速度。

##### 应用场景

* 数据处理（Data Processing）：可以快速处理数据，兼具容错性和可扩展性。
  * 迭代计算（Iterative Computation）：支持迭代计算，有效应对复杂的数据处理逻辑。
  * 流式处理（Streaming Processing）：支持秒级延迟的流处理，可支持多种外部数据源。
* 数据挖掘（Data Mining）：在海量数据基础上进行复杂的挖掘分析，可支持多种数据挖掘和机器学习算法。
  * 查询分析（Query Analysis）：支持SQL查询分析，同时提供领域特定语言（DSL）以方便操作结构化数据，并支持多种外部数据源。

##### 对比MapReduce

* 性能提升100倍。Spark的中间数据存放在内存中，对于迭代运算的效率更高。进行批处理时更高效，同时有更低的时延。
* Spark提供更多的数据集操作类型，编程模型更灵活，开发效率更高。
* 更高的容错能力（血统机制）？。

##### RDD

RDD（Resilient Distributed Dataset）是`弹性分布式数据集`。

Spark会把所有要操作的数据，加载到RDD上，



##### Shuffle

洗牌操作。跨节点数据传输





##### Transformation

在 Apache Spark 中，**Transformation（转换操作）** 是定义数据处理逻辑的核心概念，是RDD的算子类型，它表示对 RDD（弹性分布式数据集）的**惰性操作**，即不会立即执行，而是记录操作逻辑，直到遇到 **Action（触发操作）** 时才真正执行计算。

1. **惰性求值（Lazy Evaluation）**：
   Transformation 只是构建计算逻辑的蓝图，不会触发实际计算。
   ​**​示例​**​：`map`、`filter` 等操作不会立即执行，直到调用 `collect()`、`count()` 等 Action。
2. **生成新的 RDD**：
   每个 Transformation 都会基于父 RDD 生成一个新的 RDD，形成依赖链（Lineage）。
3. **支持容错**：
   通过 RDD 的依赖链（Lineage），Spark 可以在数据丢失时重新计算丢失的分区。

###### 窄依赖宽依赖

在分布式计算框架（如Apache Spark）中，**宽依赖**和**窄依赖**是用于描述RDD（弹性分布式数据集）之间依赖关系的核心概念，直接影响任务的执行优化和阶段划分。

窄依赖：父RDD的每个分区只被子RDD的一个分区所使用，子RDD的每个分区仅依赖于**父RDD的一个分区**，且数据无需跨节点传输（**无需Shuffle**）。

map、filter、flatMap、union、`coalesce`（合并分区且不触发Shuffle时）

宽依赖：父RDD的每个分区都可能被多个子RDD分区使用，子RDD的每个分区依赖于**父RDD的多个分区**，且需要**跨节点数据传输（Shuffle）**。

groupByKey、reduceByKey、distinct、join、repartition

|          |         **窄依赖**         |          **宽依赖**          |
| :------: | :------------------------: | :--------------------------: |
| **本质** |     数据不动，原地处理     |    数据必须搬家，重新分组    |
| **代价** |         快、省资源         |  慢、耗资源（网络/磁盘IO）   |
| **场景** | `map`, `filter` 等简单操作 | `groupBy`, `join` 等聚合操作 |



##### Action

在 Apache Spark 中，**Action（触发操作）** 是实际触发计算并返回结果（或输出数据）的操作。与 **Transformation（转换操作）** 不同，Action 不再是“定义计算逻辑”，而是“执行计算并输出结果”的关键步骤。

1. **触发实际计算**：
   Action 会强制 Spark 执行所有积累的 Transformation（从初始 RDD 到最终结果的整个计算链）。
2. **返回非 RDD 结果**：
   Action 的返回值通常是 ​**​标量值​**​（如 `count()` 返回一个数字）、​**​集合​**​（如 `collect()` 返回列表）或 ​**​输出到外部存储​**​（如 `saveAsTextFile()`），而不是生成新的 RDD。
3. **立即执行**：
   调用 Action 后，Spark 会生成执行计划（DAG），划分 Stage，调度 Task 到集群执行。

###### **为什么需要 Action？**

Spark 的 **惰性计算（Lazy Evaluation）** 机制决定了：

- **优化执行计划**：Spark 可以将多个 Transformation 合并为流水线操作（如 `map` → `filter` → `map`），减少中间数据落盘。
- **避免无效计算**：如果用户仅定义 Transformation 但未调用 Action，Spark 不会执行任何实际计算（节省资源）。



##### Stage

- **定义**：
  Stage 是一组​**​可以并行执行的 Task 的集合​**​，这些 Task 执行的操作之间​**​没有 Shuffle 依赖​**​。
  - **窄依赖操作**（如 `map`、`filter`）会被合并到同一个 Stage 中，形成**流水线（pipelining）执行**。
  - **宽依赖操作**（如 `groupByKey`、`join`）会触发 Stage 的划分，形成新的 Stage。
- **核心规则**：
  ​**​每遇到一个宽依赖，就会生成一个新的 Stage​**​。
  Spark 会按 Stage 的顺序依次执行，前一个 Stage 的所有 Task 完成后，才能执行下一个 Stage。

###### 为什么需要划分 Stage？

1. **优化执行效率**：
   - 窄依赖的操作可以流水线执行（无需等待前一步完成所有数据），减少中间数据落盘。
   - 宽依赖必须等待所有父分区数据就绪，因此需要划分 Stage 作为执行边界。
2. **容错恢复**：
   - 如果某个 Task 失败，只需重新执行对应 Stage 的 Task，无需回溯整个计算链。
3. **资源管理**：
   - Stage 的划分让 Spark 可以分批次调度任务，避免资源被长时间占用。



##### SparkConf

SparkConf是用来对Spark进行任务参数配置的对象。

通过键值对的形式，设置Spark任务执行时所需参数。

读取任务参数优先级：代码配置>动态参数>配置文件



##### SparkContext

SparkContext是Spark的入口，与Spark集群连接，相当于应用程序的main函数。

在 Apache Spark 中，**SparkContext** 是 Spark 应用程序的**核心入口点**，负责与集群资源管理器（如 YARN、Mesos 或 Spark Standalone）建立连接，并管理应用程序的整个生命周期。它是所有 Spark 功能的起点，开发者通过它创建 RDD、配置参数、提交任务等。

![截屏2025-05-11 21.08.39](/Users/siboo/Desktop/截屏2025-05-11 21.08.39.png)



|     **功能**     |                           **说明**                           |
| :--------------: | :----------------------------------------------------------: |
|   **连接集群**   | 与集群资源管理器通信，分配和管理计算资源（Executor、内存、CPU）。 |
|   **创建 RDD**   |     通过 `parallelize`、`textFile` 等方法创建初始 RDD。      |
|   **管理配置**   | 设置 Spark 应用参数（如 `spark.executor.memory`、`spark.default.parallelism`）。 |
|   **协调任务**   |         将 Task 分发到 Executor，监控任务执行状态。          |
| **管理共享变量** | 创建广播变量（Broadcast Variables）和累加器（Accumulators）。 |

###### SparkContext 与 SparkSession 的关系

- **Spark 1.x**：
  `SparkContext` 是唯一的入口，用于操作 RDD。
- **Spark 2.x+**：
  引入了 `SparkSession`（通过 `spark = SparkSession.builder.getOrCreate()` 创建），它是 `SparkContext` 的封装，同时支持 DataFrame、Dataset 和 SQL 操作。
  - 底层仍依赖 `SparkContext`：可通过 `spark.sparkContext` 访问。
  - **优先使用 `SparkSession`**：除非需要直接操作 RDD。
  - 封装了SparkConf和SparkContext，方便用户使用各种API（SparkContext、StreamContext、SQLContext）

##### SparkSQL

在 Apache Spark 中，**Spark SQL** 是专为**结构化数据处理**设计的核心模块，它允许开发者使用 SQL 查询或 DataFrame/Dataset API 对结构化数据执行高性能分析，同时无缝集成 Spark 的分布式计算能力。

SQL语句通过SparkSQL模块解析为RDD执行计划，交给SparkCore执行。

1. **统一数据处理**：
   - 支持 SQL 语法、DataFrame/Dataset API 和 RDD 操作，可混合使用。
   - 直接处理多种数据源：JSON、Parquet、Hive、CSV、JDBC 等。
2. **高性能优化**：
   - 通过 **Catalyst 优化器** 自动优化查询计划，提升执行效率。
   - **Tungsten 引擎**：使用堆外内存和二进制格式，减少序列化开销。
3. **与 Hive 集成**：
   - 兼容 Hive 的元数据、UDF 和 HQL 查询，可直接访问 Hive 表（需配置 `hive-site.xml`）。
4. **结构化流处理（Structured Streaming）**：
   - 以 DataFrame/Dataset 为基础，支持实时数据流的 SQL 查询。

###### **DataFrame 和 Dataset 的定义**



|   **特性**   |                 **DataFrame**                  |                  **Dataset**                   |
| :----------: | :--------------------------------------------: | :--------------------------------------------: |
|   **本质**   |   一种特殊的 `Dataset`（即 `Dataset[Row]`）    |       强类型 API（仅支持 Scala 和 Java）       |
| **数据结构** |   按列组织的分布式数据集合，具有 Schema 信息   | 类型化的分布式数据集合（如 `Dataset[Person]`） |
| **类型安全** | 运行时类型检查（如字段名错误在运行时抛出异常） | 编译时类型检查（字段名或类型错误在编译时捕获） |
| **适用语言** |             Scala、Java、Python、R             |                  Scala、Java                   |







### 实时检索场景



### 实时流处理场景



