## 大数据



### 离线批处理场景

离线批处理，是指对海量历史数据进行处理和分析，生成结果数据，供下一步使用的过程。

* 处理时延要求不高
* 处理数据量大，占用存储资源多
* 处理数据格式多样
* 支持SQL类作业和自定义作业

离线批处理流程

![image-20250406133355971](大数据.assets/image-20250406133355971.png)



#### HDFS

`HDFS(Hadoop Distributed File System)`是基于Google发布的`GFS(Google File System)`论文设计开发的分布式文件系统，为各种批处理引擎提供数据存储，可以存储各种文件格式数据。

* 高容错性：认为硬件不可靠。由于HDFS采用数据多副本方案，所以部分硬件的损坏不会导致全部数据的丢失。
* 高吞吐量：为大量数据访问的应用提供高吞吐量支持。
* 大文件存储：适合`大文件（TB-PB级别）`存储存储与访问、`流式数据`访问；不适合大量小文件存储，数据的随机写入和低延迟读取。
* 简单一致性模型：适合于一次写入多次读取 (write-once-read-many) 的访问模型。支持将内容追加到文件末尾， 但不支持数据的随机访问，不能从文件任意位置新增数据。
* 跨平台移植性

##### HDFS架构

![image-20250406135032095](大数据.assets/image-20250406135032095.png)



HDFS为主/从架构，由单个`NameNode(NN)`和多个`DataNode(DN)`组成：

* `NameNode`：负责执行有关`文件系统命名空间`的操作，例如打开，关闭、重命名文件和目录等，并记录对命名空间的修改。 它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。HDFS`文件系统命名空间`的层次结构与Linux系统类似， 支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但不支持硬链接和软连接。
* `DataNode`：负责执行来自文件系统客户端的读写请求，执行块的创建，删除等操作。

##### 数据复制

为了保证容错性，HDFS提供了数据复制机制。HDFS将每一个文件存储为一系列**块**，每个块由多个**副本**来保证容错，块的大小和**复制因子**可以自行配置（默认情况下，块大小是`128M`，默认复制因子是`3`）。

大型的HDFS实例在通常分布在多个机架的多台服务器上，不同机架上的两台服务器之间通过交换机进行通讯。在大多数情况下，同一机架中的服务器间的网络带宽大于不同机架中的服务器之间的带宽。

因此HDFS采用`机架感知副本放置策略`，当复制因子为3时，HDFS的放置策略是： 

？在写入程序位于  datanode 上时，就优先将写入文件的一个副本放置在该  datanode 上，否则放在随 机 datanode 上。之后在另一个远程机架上的任意一个节点上放置另一个副本，并在该机架上的另一 个节点上放置最后一个副本。此策略可以减少机架间的写入流量，从而提高写入性能。

如果复制因子大于 3，则随机确定第 4 个和之后副本的放置位置，同时保持每个机架的副本数量低于上 限，上限值通常为（复制系数 - 1）/机架数量 + 2，需要注意的是不允许同一个  dataNode 上具有同一个块的多个副本。



##### HDFS回收站机制

在HDFS删除文件时，其实是将文件放入回收站，回收站可以用来快速恢复误删的文件。

可以设置时间阈值（单位：分钟），当回收站里的文件存放时间超过这个阈值或清空回收站时，文件才会被彻底删除，并释放占用的数据块。

Hadoop回收站trash，默认是关闭的，若开启需要修改配置文件`core-site.xml`。

```xml
<property>
	<name>fs.trash.interval</name>
	<value>1440</value>
</property>
```



如何删除数据？

##### 常用Shell命令

```shell
# 显示文件内容
hdfs dfs -cat
# 显示目录列表
hdfs dfs -ls
# 
hdfs dfs -rm
hdfs dfs -put 
hdfs dfs -get
hdfs dfs -mkdir
# 修改文件或目录的权限
hdfs dfs -chmod
# 修改文件或目录的所有者和所属组
hdfs dfs -chown
# 安全模式操作
hdfs dfsadmin -safemode
# 报告服务状态
hdfs dfsadmin -report

```

#### MapReduce

Hadoop MapReduce 是一个分布式计算框架，用于编写批处理应用程序。编写好的程序可以提交到  Hadoop 集群上用于并行处理大规模的数据集



#### Hive

Hive是基于Hadoop的数据仓库软件，可以查询和管理PB级别的分布式数据。

Hive特性：

* 灵活`ETL（Extract/Transform/Load）`
* 支持MapReduce、Tez、Spark多种计算引擎
* 可直接访问HDFS文件以及HBase
* 易用易编程



##### Hive架构



##### Hive数据存储模型

![image-20250508214033566](/Users/siboo/Library/Application Support/typora-user-images/image-20250508214033566.png)

Hive内部表和外部表的区别



##### 数据集市

数据集市（Data Mart）：也叫数据市场，数据集市就是满足特定用户的需求，按照多维的方式存储数据，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体。

##### 数据仓库

为满足各类零散分析的需求，通过数据分层和数据模型的方式，并以基于业务和应用的角度将数据进行模块化的存储。

数据仓库分层：

* ODS（Operational Data Store）：原始数据层。
* DWD（Data WareHouse Detail）：结构和粒度与原始数据保持一致，简单清洗。
* DWS（Data WareHouse Service）：以DWD为基础，进行轻度汇总。
* ADS（Application Data Store）：为各种统计报表提供数据。

分层优点：

* 复杂问题简单化：将任务分解为多个步骤完成，每一层处理单一的任务。
* 减少重复开发：规范数据分层，通过中间层数据，减少重复计算，增加计算结果的复用性。
* 隔离原始数据：避免数据异常和数据敏感，使真实数据和统计数据解耦。

#### Spark

Spark是基于内存的分布式批处理系统，它把任务拆分，分配到多个CPU上进行处理，处理数据时产生的中间产物（计算结果）存放在内存中，减少了对磁盘的IO操作，提升了数据处理速度。

##### 应用场景

* 数据处理（Data Processing）：可以快速处理数据，兼具容错性和可扩展性。
  * 迭代计算（Iterative Computation）：支持迭代计算，有效应对复杂的数据处理逻辑。
  * 流式处理（Streaming Processing）：支持秒级延迟的流处理，可支持多种外部数据源。
* 数据挖掘（Data Mining）：在海量数据基础上进行复杂的挖掘分析，可支持多种数据挖掘和机器学习算法。
  * 查询分析（Query Analysis）：支持SQL查询分析，同时提供领域特定语言（DSL）以方便操作结构化数据，并支持多种外部数据源。

##### 对比MapReduce

* 性能提升100倍。Spark的中间数据存放在内存中，对于迭代运算的效率更高。进行批处理时更高效，同时有更低的时延。
* Spark提供更多的数据集操作类型，编程模型更灵活，开发效率更高。
* 更高的容错能力（血统机制）？。

##### RDD

RDD（Resilient Distributed Dataset）是`弹性分布式数据集`。

Spark会把所有要操作的数据，加载到RDD上，



##### Shuffle

洗牌操作。跨节点数据传输





##### Transformation

在 Apache Spark 中，**Transformation（转换操作）** 是定义数据处理逻辑的核心概念，是RDD的算子类型，它表示对 RDD（弹性分布式数据集）的**惰性操作**，即不会立即执行，而是记录操作逻辑，直到遇到 **Action（触发操作）** 时才真正执行计算。

1. **惰性求值（Lazy Evaluation）**：
   Transformation 只是构建计算逻辑的蓝图，不会触发实际计算。
   ​**​示例​**​：`map`、`filter` 等操作不会立即执行，直到调用 `collect()`、`count()` 等 Action。
2. **生成新的 RDD**：
   每个 Transformation 都会基于父 RDD 生成一个新的 RDD，形成依赖链（Lineage）。
3. **支持容错**：
   通过 RDD 的依赖链（Lineage），Spark 可以在数据丢失时重新计算丢失的分区。

###### 窄依赖宽依赖

在分布式计算框架（如Apache Spark）中，**宽依赖**和**窄依赖**是用于描述RDD（弹性分布式数据集）之间依赖关系的核心概念，直接影响任务的执行优化和阶段划分。

窄依赖：父RDD的每个分区只被子RDD的一个分区所使用，子RDD的每个分区仅依赖于**父RDD的一个分区**，且数据无需跨节点传输（**无需Shuffle**）。

map、filter、flatMap、union、`coalesce`（合并分区且不触发Shuffle时）

宽依赖：父RDD的每个分区都可能被多个子RDD分区使用，子RDD的每个分区依赖于**父RDD的多个分区**，且需要**跨节点数据传输（Shuffle）**。

groupByKey、reduceByKey、distinct、join、repartition

|          |         **窄依赖**         |          **宽依赖**          |
| :------: | :------------------------: | :--------------------------: |
| **本质** |     数据不动，原地处理     |    数据必须搬家，重新分组    |
| **代价** |         快、省资源         |  慢、耗资源（网络/磁盘IO）   |
| **场景** | `map`, `filter` 等简单操作 | `groupBy`, `join` 等聚合操作 |



##### Action

在 Apache Spark 中，**Action（触发操作）** 是实际触发计算并返回结果（或输出数据）的操作。与 **Transformation（转换操作）** 不同，Action 不再是“定义计算逻辑”，而是“执行计算并输出结果”的关键步骤。

1. **触发实际计算**：
   Action 会强制 Spark 执行所有积累的 Transformation（从初始 RDD 到最终结果的整个计算链）。
2. **返回非 RDD 结果**：
   Action 的返回值通常是 ​**​标量值​**​（如 `count()` 返回一个数字）、​**​集合​**​（如 `collect()` 返回列表）或 ​**​输出到外部存储​**​（如 `saveAsTextFile()`），而不是生成新的 RDD。
3. **立即执行**：
   调用 Action 后，Spark 会生成执行计划（DAG），划分 Stage，调度 Task 到集群执行。

###### **为什么需要 Action？**

Spark 的 **惰性计算（Lazy Evaluation）** 机制决定了：

- **优化执行计划**：Spark 可以将多个 Transformation 合并为流水线操作（如 `map` → `filter` → `map`），减少中间数据落盘。
- **避免无效计算**：如果用户仅定义 Transformation 但未调用 Action，Spark 不会执行任何实际计算（节省资源）。



##### Stage

- **定义**：
  Stage 是一组​**​可以并行执行的 Task 的集合​**​，这些 Task 执行的操作之间​**​没有 Shuffle 依赖​**​。
  - **窄依赖操作**（如 `map`、`filter`）会被合并到同一个 Stage 中，形成**流水线（pipelining）执行**。
  - **宽依赖操作**（如 `groupByKey`、`join`）会触发 Stage 的划分，形成新的 Stage。
- **核心规则**：
  ​**​每遇到一个宽依赖，就会生成一个新的 Stage​**​。
  Spark 会按 Stage 的顺序依次执行，前一个 Stage 的所有 Task 完成后，才能执行下一个 Stage。

###### 为什么需要划分 Stage？

1. **优化执行效率**：
   - 窄依赖的操作可以流水线执行（无需等待前一步完成所有数据），减少中间数据落盘。
   - 宽依赖必须等待所有父分区数据就绪，因此需要划分 Stage 作为执行边界。
2. **容错恢复**：
   - 如果某个 Task 失败，只需重新执行对应 Stage 的 Task，无需回溯整个计算链。
3. **资源管理**：
   - Stage 的划分让 Spark 可以分批次调度任务，避免资源被长时间占用。



##### SparkConf

SparkConf是用来对Spark进行任务参数配置的对象。

通过键值对的形式，设置Spark任务执行时所需参数。

读取任务参数优先级：代码配置>动态参数>配置文件



##### SparkContext

SparkContext是Spark的入口，与Spark集群连接，相当于应用程序的main函数。

在 Apache Spark 中，**SparkContext** 是 Spark 应用程序的**核心入口点**，负责与集群资源管理器（如 YARN、Mesos 或 Spark Standalone）建立连接，并管理应用程序的整个生命周期。它是所有 Spark 功能的起点，开发者通过它创建 RDD、配置参数、提交任务等。

![截屏2025-05-11 21.08.39](/Users/siboo/Desktop/截屏2025-05-11 21.08.39.png)



|     **功能**     |                           **说明**                           |
| :--------------: | :----------------------------------------------------------: |
|   **连接集群**   | 与集群资源管理器通信，分配和管理计算资源（Executor、内存、CPU）。 |
|   **创建 RDD**   |     通过 `parallelize`、`textFile` 等方法创建初始 RDD。      |
|   **管理配置**   | 设置 Spark 应用参数（如 `spark.executor.memory`、`spark.default.parallelism`）。 |
|   **协调任务**   |         将 Task 分发到 Executor，监控任务执行状态。          |
| **管理共享变量** | 创建广播变量（Broadcast Variables）和累加器（Accumulators）。 |

###### SparkContext 与 SparkSession 的关系

- **Spark 1.x**：
  `SparkContext` 是唯一的入口，用于操作 RDD。
- **Spark 2.x+**：
  引入了 `SparkSession`（通过 `spark = SparkSession.builder.getOrCreate()` 创建），它是 `SparkContext` 的封装，同时支持 DataFrame、Dataset 和 SQL 操作。
  - 底层仍依赖 `SparkContext`：可通过 `spark.sparkContext` 访问。
  - **优先使用 `SparkSession`**：除非需要直接操作 RDD。
  - 封装了SparkConf和SparkContext，方便用户使用各种API（SparkContext、StreamContext、SQLContext）

##### SparkSQL







### 实时检索场景



### 实时流处理场景



